# Тестовое задание для отбора на Летнюю ИТ-школу КРОК по разработке

## Условие задания
Однажды теплым летним вечером вас посетила идея разработать свое расширение для браузера для построения ссылочного графа. Что это означает на практике — ваше расширение активируется на какой-либо web-странице сайта, определяет список уникальных внешних ссылок, после чего повторяет алгоритм для каждой ссылки. Максимальная глубина поиска, визуализация собранных данных и прочие вопросы вы сочли вторичными, а начать решено было с малого — с обходчика страниц, который бы находил уникальные ссылки.

В процессе проектирования вы решили немного упростить ваш mvp и в итоге поставили себе задачу следующим образом: реализовать поиск всех уникальных ресурсов (доменов) в рамках страницы, на которые есть ссылки. При этом, формулируя задачу, вы сделали следующие допущения:
- Доменом считается запись вида example.com;
- Поддомен, например, sub.example.com,  считается отдельным ресурсом;
- Протокол (при наличии) не имеет значения.

Требования к реализации:
1. Реализация должна содержать, как минимум, одну процедуру (функцию/метод), отвечающую за поиск уникальных ресурсов, и должна быть описана в readme.md в соответствии с чек-листом;
2. В качестве входных данных программа использует реальный html-файл (page.html)	, считав который, начинает выполнять поиск;
3. Процедура (функция/метод) поиска должна возвращать строку в формате json следующего формата:
   - {«sites»: [«mail.ru», «rbc.ru», «ria.ru»]}
4. Найденные в соответствии с условием задачи домены должны выводиться в нижнем регистре без указания протокола и «www» в алфавитном порядке.

## Автор решения
### Захаренко Георгий Игоревич (geo.zakharenko@mail.ru)
## Описание реализации
Реализация состоит из двух классов:
- Класс Crawler (основной класс, производящий поиск всех уникальных ресурсов (доменов) в рамках страницы, на которые есть ссылки)
- Класс SerWrapper (класс-обёртка, использовался с целью указать, что уникальные домены принадлежат множеству sites
в json-файле)

Crawler использует следующие методы:
- Метод takeUniqueSitesFromHTML. Выполняет поиск уникальных доменов и поддоменов. Создаётся document типа Document,
в котором хранится html-файл, полученный из resources. В файле идёт поиск всех элементов имеющих атрибут href (ссылку),
и для каждого такого элемента извлекается абсолютный URL. Каждый URL преобразуется в домен нужного формата (example.com).
Все готовые домены кладутся в коллекцию (Set) и возвращаются в вызывающий метод.
- Метод extractDomain. Возвращает домен нужного формата из созданного полученной ссылкой хоста.
- Метод convertToJson. Конвертирует экземпляр класса SetWrapper в формат json-файла.


## Инструкция по сборке и запуску решения
За сборку проекта отвечает Maven. Настройка сборки содержится в pom.xml

Необходимый html-файл необходимо положить в раздел resources. После, методу takeUniqueSitesFromHTML необходимо
передать аргумент в виде пути к файлу из раздела (Path from Content root).

Запуск в консоли:
1. Перейти в директорию с проектом.
2. Ввести в консоль:
java -jar target/school2024-test-task3-1.0-SNAPSHOT-jar-with-dependencies.jar